{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sri2590/Vibot-Chatbot/blob/main/agent_emulator_hybrid_search_rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfd1a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "adfd1a3d",
        "outputId": "4c2147ad-4469-4b39-9de7-9c5995ecc498"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-519605928>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultHttpxClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableBranch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#nihaal commented here\n",
        "#Srinidhi commented here\n",
        "from langchain_openai import ChatOpenAI\n",
        "from openai import OpenAI, DefaultHttpxClient\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda, RunnableBranch\n",
        "from langchain_core.runnables.passthrough import RunnableAssign\n",
        "from langchain_core.documents.base import Document\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import chromadb\n",
        "import sqlite3\n",
        "from langserve import RemoteRunnable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b71f2c2",
      "metadata": {
        "id": "7b71f2c2"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=\"\",\n",
        "    base_url=\"https://llm.monsterapi.ai/v1/\",\n",
        "    http_client=DefaultHttpxClient(verify = False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba1edc3",
      "metadata": {
        "id": "bba1edc3"
      },
      "outputs": [],
      "source": [
        "llm.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e40ae9",
      "metadata": {
        "id": "b2e40ae9"
      },
      "outputs": [],
      "source": [
        "decision_prompt =  PromptTemplate.from_template(\"\"\"You have access to the following tools:\n",
        "            1. retrieve -  call this tool when you want to know information to answer a question.\n",
        "            2. greet - call this tool when the user greets you or asks questions like who are you. In summary when they are having a casual conversation.\n",
        "            User has asked the following question {query}\n",
        "            Which tool will you use? just return the name of the tool alone and nothing else.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fadd6857",
      "metadata": {
        "id": "fadd6857"
      },
      "outputs": [],
      "source": [
        "decision_chain = decision_prompt|llm|StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd0871d",
      "metadata": {
        "id": "6cd0871d"
      },
      "outputs": [],
      "source": [
        "decision_chain.invoke({\"query\":\"Explain relative grading in detail\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92199888",
      "metadata": {
        "id": "92199888"
      },
      "outputs": [],
      "source": [
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"BAAI/bge-small-en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672f9661",
      "metadata": {
        "id": "672f9661"
      },
      "outputs": [],
      "source": [
        "persistent_client = chromadb.PersistentClient(path=\"Vectorstore1\")\n",
        "\n",
        "vectorstore = Chroma(client=persistent_client,collection_name=\"Questions\",embedding_function=embedding_function)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={'k': 12})\n",
        "retriever.invoke(\"What is FC?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "961538e9",
      "metadata": {
        "id": "961538e9"
      },
      "outputs": [],
      "source": [
        "conn = sqlite3.connect('chunk_database_mixtral.db',check_same_thread=False)\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b81ca6e",
      "metadata": {
        "id": "4b81ca6e"
      },
      "outputs": [],
      "source": [
        "def retrieve_chunk(chunk_id):\n",
        "    cursor.execute(\"SELECT chunk FROM CHUNKS WHERE chunk_id=?\", (chunk_id,))\n",
        "    result = cursor.fetchone()\n",
        "    if result:\n",
        "        return result[0]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab691c41",
      "metadata": {
        "id": "ab691c41"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bae0c3",
      "metadata": {
        "id": "16bae0c3"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"Admission-rewritten-full.pdf\")\n",
        "documents = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4c8934",
      "metadata": {
        "id": "fa4c8934"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a5f5be",
      "metadata": {
        "id": "e2a5f5be"
      },
      "outputs": [],
      "source": [
        "class SimpleTextSearch:\n",
        "    def __init__(self,docs):\n",
        "        self.__docs =  [doc.page_content for doc in docs]\n",
        "    def search(self,query,top_k=2):\n",
        "        query_terms = set(query.lower().split())\n",
        "        scored_sentences = []\n",
        "        for sentence in self.__docs:\n",
        "            # Count matching terms\n",
        "            sentence_terms = set(sentence.lower().split())\n",
        "            matching_terms = query_terms.intersection(sentence_terms)\n",
        "\n",
        "            # Calculate score based on proportion of query terms found\n",
        "            if matching_terms:\n",
        "                score = len(matching_terms) / len(query_terms)\n",
        "                scored_sentences.append((sentence, score))\n",
        "\n",
        "        # Sort by score and return top k\n",
        "        scored_sentences.sort(key=lambda x: x[1], reverse=True)\n",
        "        return scored_sentences[:top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b94c7df",
      "metadata": {
        "id": "1b94c7df"
      },
      "outputs": [],
      "source": [
        "TextRetriever = SimpleTextSearch(docs=texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedf9201",
      "metadata": {
        "id": "bedf9201"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a06e36e",
      "metadata": {
        "id": "3a06e36e"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: dict) -> str:\n",
        "    query = state[\"query\"]\n",
        "    questions = retriever.invoke(query)\n",
        "    chunk_ids = set()\n",
        "    for question in questions:\n",
        "        chunk_ids.add(question.metadata['chunk_id'])\n",
        "    chunks = []\n",
        "    for chunk_id in chunk_ids:\n",
        "        chunks.append(Document(page_content=retrieve_chunk(chunk_id)))\n",
        "    chunk_string = \"\\n\\n\".join([d.page_content for d in chunks])\n",
        "    keyword_docs = TextRetriever.search(query,2)\n",
        "    keyword_string = \"\\n\\n\".join([d[0] for d in keyword_docs])\n",
        "    return  f\"\"\"Documents retrieved based on semantic similarity:{chunk_string} \\n\\nDocuments retrieved based on Keyword search:{keyword_string}\\n\\n\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f73218",
      "metadata": {
        "id": "78f73218"
      },
      "outputs": [],
      "source": [
        "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
        "compressor = CrossEncoderReranker(model=model, top_n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba1a22f",
      "metadata": {
        "id": "0ba1a22f"
      },
      "outputs": [],
      "source": [
        "def retrieve_and_rerank(state: dict) -> str:\n",
        "    query = state[\"query\"]\n",
        "    questions = retriever.invoke(query)\n",
        "    chunk_ids = set()\n",
        "    for question in questions:\n",
        "        chunk_ids.add(question.metadata['chunk_id'])\n",
        "    chunks = []\n",
        "    for chunk_id in chunk_ids:\n",
        "        chunks.append(Document(page_content=retrieve_chunk(chunk_id)))\n",
        "    keyword_docs = TextRetriever.search(query,2)\n",
        "    for chunk in keyword_docs:\n",
        "        chunks.append(Document(page_content=chunk[0]))\n",
        "    reranked_docs = compressor.compress_documents(chunks,query)\n",
        "    return \"\\n\\n\".join([d.page_content for d in reranked_docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec218c01",
      "metadata": {
        "id": "ec218c01"
      },
      "outputs": [],
      "source": [
        "retrieval_prompt = PromptTemplate.from_template(\"\"\"You are VIBOT an assistant designated to answer questions related to VIT university.\n",
        "                                                   Answer the following question {query}\n",
        "                                                   Here are some information that will be useful to answer question: {context}\n",
        "                                                   Answer precisely unless you are asked to answer in detail.\n",
        "                                                   Try to avoid providing additional unwanted information to users. Answer to the point.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9786c11d",
      "metadata": {
        "id": "9786c11d"
      },
      "outputs": [],
      "source": [
        "paraphrase_prompt = PromptTemplate.from_template(\"\"\"You will be provided with a question and and answer that was created to answer the question.\n",
        "                                                    The answer may have impurities due to a simple text search remove the irrevelent parts from\n",
        "                                                    the answer that is not related to the question.Just return the pharaphrased answer and nothing.\n",
        "                                                    In any case remove only the unwanted parts from the answer.\n",
        "                                                    Question:{query}\n",
        "                                                    Answer: {answer}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f8b765",
      "metadata": {
        "id": "a3f8b765"
      },
      "outputs": [],
      "source": [
        "#answer_with_retrieval = RunnableAssign({\"answer\":retrieval_prompt | llm | StrOutputParser()}) | paraphrase_prompt | llm | StrOutputParser()\n",
        "answer_with_retrieval = retrieval_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12177551",
      "metadata": {
        "id": "12177551"
      },
      "outputs": [],
      "source": [
        "generic_prompt = PromptTemplate.from_template(\"\"\"You are VIBOT an assistant designated to answer questions related to VIT university.\n",
        "                  Here are some information about you:\n",
        "                  You are developed in IEDC lab at VIT Chennai.\n",
        "                  You think your developers are legendary.\n",
        "                  You will not resopnd to harmful or disrespectful queries.\n",
        "                  User told : {query} respond to the user respectfully.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c3bed3",
      "metadata": {
        "id": "22c3bed3"
      },
      "outputs": [],
      "source": [
        "answer_without_retrieval = generic_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aee16c",
      "metadata": {
        "id": "f4aee16c"
      },
      "outputs": [],
      "source": [
        "answer_without_retrieval.invoke({\"query\":\"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b84a4c0a",
      "metadata": {
        "id": "b84a4c0a"
      },
      "outputs": [],
      "source": [
        "branch = RunnableBranch(\n",
        "    (lambda x: \"retrieve\" in x[\"action\"].lower(),RunnableAssign({\"context\":RunnableLambda(retrieve_and_rerank)})| answer_with_retrieval),\n",
        "    answer_without_retrieval,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5eec75",
      "metadata": {
        "id": "ab5eec75"
      },
      "outputs": [],
      "source": [
        "full_chain = RunnableAssign({\"action\": decision_chain}) | branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a299b34",
      "metadata": {
        "id": "0a299b34"
      },
      "outputs": [],
      "source": [
        "out = full_chain.invoke({\"query\":\"What is FFCS?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26351db",
      "metadata": {
        "id": "f26351db"
      },
      "outputs": [],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769a5263",
      "metadata": {
        "id": "769a5263"
      },
      "outputs": [],
      "source": [
        "out1 = full_chain.invoke({\"query\":\"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0dc70f",
      "metadata": {
        "id": "ff0dc70f"
      },
      "outputs": [],
      "source": [
        "out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2f066b",
      "metadata": {
        "id": "ef2f066b"
      },
      "outputs": [],
      "source": [
        "out1 = full_chain.invoke({\"query\":\"In alpha block projector is not working and teachers are facing difficulties could you help!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f05304",
      "metadata": {
        "id": "38f05304"
      },
      "outputs": [],
      "source": [
        "out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a447d5f8",
      "metadata": {
        "id": "a447d5f8"
      },
      "outputs": [],
      "source": [
        "type(out1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b7fc59",
      "metadata": {
        "id": "84b7fc59"
      },
      "outputs": [],
      "source": [
        "def llama3_chat():\n",
        "    print(\"Hello!!!! I am llama3 and I can help with your document. \\nIf you want to stop you can enter STOP at any point!\")\n",
        "    print()\n",
        "    print(\"-------------------------------------------------------------------------------------\")\n",
        "    question = input()\n",
        "    while question != \"~\":\n",
        "        out  = full_chain.invoke({\"query\":question})\n",
        "        print(out)\n",
        "        print(\"\\nIs there anything else you would like my help with?\")\n",
        "        print(\"-------------------------------------------------------------------------------------\")\n",
        "        question = input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f62b78b",
      "metadata": {
        "id": "9f62b78b"
      },
      "outputs": [],
      "source": [
        "llama3_chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65771bec",
      "metadata": {
        "id": "65771bec"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482971f8",
      "metadata": {
        "id": "482971f8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d1a4c50",
      "metadata": {
        "id": "9d1a4c50"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7aa976",
      "metadata": {
        "id": "7b7aa976"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6e66d9",
      "metadata": {
        "id": "dd6e66d9"
      },
      "outputs": [],
      "source": [
        "output = {}\n",
        "for i in tqdm.tqdm(range(len(df))):\n",
        "    try:\n",
        "        question = df[\"question\"][i]\n",
        "        correct_answer    = df[\"answer\"][i]\n",
        "        generated_answer  = full_chain.invoke({\"query\":question})\n",
        "        output[question] = [correct_answer,generated_answer]\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbeab14",
      "metadata": {
        "id": "fbbeab14"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "    json.dump(output, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2a2960",
      "metadata": {
        "id": "bd2a2960"
      },
      "outputs": [],
      "source": [
        "output['who are u']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8763d1fb",
      "metadata": {
        "id": "8763d1fb"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a996f5dd",
      "metadata": {
        "id": "a996f5dd"
      },
      "outputs": [],
      "source": [
        "filename = 'output_1.csv'\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(filename, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['question','correct_answer','generated_answer'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for question, answers in output.items():\n",
        "        # Assuming the first item in the list is the correct answer and the second is the generated answer\n",
        "        correct_answer = answers[0]\n",
        "        answer = answers[1]\n",
        "        writer.writerow([question,correct_answer,answer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c0ab90",
      "metadata": {
        "id": "43c0ab90"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}